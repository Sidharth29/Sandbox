{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Framework in Llama Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Use\n",
    "\n",
    "The FunctionTool module can be used here to convert any function into a tool that the agent could call if it feels the necessity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import nest_asyncio\n",
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.agent.introspective import (\n",
    "    ToolInteractiveReflectionAgentWorker,\n",
    ")\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Keys\n",
    "API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41640c91aff77e824e7f7a11f984c49a\n"
     ]
    }
   ],
   "source": [
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. To access external API data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city_name, units='imperial'):\n",
    "    \"\"\"\n",
    "    Function that taken in a city name and units and returns the temperature and description of weather\n",
    "\n",
    "    Args:\n",
    "    city_name: The name of the city (ex: Los Angeles)\n",
    "    units: The measurement units for tempreature (Options: imperial - fahreinheit, metric - celsius), Default: fahrenheit (imperial)\n",
    "\n",
    "    Return:\n",
    "    city: Name of the City\n",
    "    temperature: the temperature in the provided measurement units\n",
    "    description: the short description of the weather\n",
    "    \"\"\"\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "    complete_url = base_url + \"appid=\" + API_KEY + \"&q=\" + city_name + \"&units=\" + units\n",
    "    \n",
    "    response = requests.get(complete_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "        return {\n",
    "            'city': city_name,\n",
    "            'temperature': weather_data['main']['temp'],\n",
    "            'description': weather_data['weather'][0]['description']\n",
    "        }\n",
    "    else:\n",
    "        return {'error': 'Failed to retrieve weather data', 'status_code': response.status_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare tool\n",
    "weather_fetch_tool = FunctionTool.from_defaults(fn=get_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance of simple function call using the OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: get_weather with args: {\"city_name\": \"San Jose\"}\n",
      "=== Function Output ===\n",
      "{'city': 'San Jose', 'temperature': 76.59, 'description': 'scattered clouds'}\n",
      "{'city': 'San Jose', 'temperature': 76.59, 'description': 'scattered clouds'}\n"
     ]
    }
   ],
   "source": [
    "# Use query engine with the tool\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY)\n",
    "response = llm.predict_and_call(\n",
    "    [weather_fetch_tool], \n",
    "    \"How is the weather in San Jose right now?\", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of Runner and Worker\n",
    "\n",
    "Runner - Manages/Orchestrates the different tasks once the query is received, oversees the outputs of the worker, returns final response when ready\n",
    "\n",
    "Worker - Does the actual execution of the individual tasks using the available tools\n",
    "\n",
    "![components](/Users/chandrasekaransidha/personal/sandbox/img/agent_components.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [weather_fetch_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Who is Connor McGregor?\n",
      "=== LLM Response ===\n",
      "Connor McGregor is a professional mixed martial artist and former UFC (Ultimate Fighting Championship) featherweight and lightweight champion. He is known for his charismatic personality, trash-talking, and fighting skills inside the octagon. McGregor is one of the most popular and successful fighters in the history of MMA (Mixed Martial Arts).\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Who is Connor McGregor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Is it a good day to go running outside, I'm in Hayward?\n",
      "=== Calling Function ===\n",
      "Calling function: get_weather with args: {\"city_name\": \"Hayward\"}\n",
      "=== Function Output ===\n",
      "{'city': 'Hayward', 'temperature': 68.27, 'description': 'clear sky'}\n",
      "=== LLM Response ===\n",
      "The weather in Hayward is currently 68.27°F with a clear sky. It seems like a good day to go running outside!\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Is it a good day to go running outside, I'm in Hayward?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: get_weather\n",
      "Action Input: {'city_name': 'Hayward', 'units': 'imperial'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'city': 'Hayward', 'temperature': 68.27, 'description': 'clear sky'}\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The current temperature in Hayward is 68.27°F with clear skies. It seems like a good day to go running outside!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Using the ReAct Agent\n",
    "\n",
    "agent = ReActAgent.from_tools([weather_fetch_tool], llm=llm, verbose=True)\n",
    "\n",
    "\n",
    "response = agent.chat(\"Is it a good day to go running outside, I'm in Hayward?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Auto Retrieval: To perform metadata filtering while retrieving data (RAG) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9d25aa1809562b78450ffbaf528b6067bd8b0570a3ba43fb0c8aa79f9941b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
